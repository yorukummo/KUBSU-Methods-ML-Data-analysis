{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Знакомство-с-библиотекой-Scikit-Learn\" data-toc-modified-id=\"Знакомство-с-библиотекой-Scikit-Learn-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Знакомство с библиотекой Scikit-Learn</a></span><ul class=\"toc-item\"><li><span><a href=\"#Представление-данных-в-Scikit-Learn\" data-toc-modified-id=\"Представление-данных-в-Scikit-Learn-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Представление данных в Scikit-Learn</a></span><ul class=\"toc-item\"><li><span><a href=\"#Данные-как-таблица\" data-toc-modified-id=\"Данные-как-таблица-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Данные как таблица</a></span><ul class=\"toc-item\"><li><span><a href=\"#Матрица-признаков\" data-toc-modified-id=\"Матрица-признаков-1.1.1.1\"><span class=\"toc-item-num\">1.1.1.1&nbsp;&nbsp;</span>Матрица признаков</a></span></li><li><span><a href=\"#Целевой-массив\" data-toc-modified-id=\"Целевой-массив-1.1.1.2\"><span class=\"toc-item-num\">1.1.1.2&nbsp;&nbsp;</span>Целевой массив</a></span></li></ul></li></ul></li><li><span><a href=\"#API-статистического-оценивания-библиотеки-Scikit-Learn\" data-toc-modified-id=\"API-статистического-оценивания-библиотеки-Scikit-Learn-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>API статистического оценивания библиотеки Scikit-Learn</a></span><ul class=\"toc-item\"><li><span><a href=\"#Основы-API-статистического-оценивания\" data-toc-modified-id=\"Основы-API-статистического-оценивания-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Основы API статистического оценивания</a></span></li><li><span><a href=\"#Пример-обучения-с-учителем:-простая-линейная-регрессия\" data-toc-modified-id=\"Пример-обучения-с-учителем:-простая-линейная-регрессия-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Пример обучения с учителем: простая линейная регрессия</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Выбор-класса-модели.\" data-toc-modified-id=\"1.-Выбор-класса-модели.-1.2.2.1\"><span class=\"toc-item-num\">1.2.2.1&nbsp;&nbsp;</span>1. Выбор класса модели.</a></span></li><li><span><a href=\"#2.-Выбор-гиперпараметров-модели.\" data-toc-modified-id=\"2.-Выбор-гиперпараметров-модели.-1.2.2.2\"><span class=\"toc-item-num\">1.2.2.2&nbsp;&nbsp;</span>2. Выбор гиперпараметров модели.</a></span></li><li><span><a href=\"#3.-Формирование-из-данных-матриц-признаков-и-целевого-вектора.\" data-toc-modified-id=\"3.-Формирование-из-данных-матриц-признаков-и-целевого-вектора.-1.2.2.3\"><span class=\"toc-item-num\">1.2.2.3&nbsp;&nbsp;</span>3. Формирование из данных матриц признаков и целевого вектора.</a></span></li><li><span><a href=\"#4.-Обучение-модели-на-наших-данных.\" data-toc-modified-id=\"4.-Обучение-модели-на-наших-данных.-1.2.2.4\"><span class=\"toc-item-num\">1.2.2.4&nbsp;&nbsp;</span>4. Обучение модели на наших данных.</a></span></li><li><span><a href=\"#5.-Предсказание-меток-для-новых-данных.\" data-toc-modified-id=\"5.-Предсказание-меток-для-новых-данных.-1.2.2.5\"><span class=\"toc-item-num\">1.2.2.5&nbsp;&nbsp;</span>5. Предсказание меток для новых данных.</a></span></li></ul></li><li><span><a href=\"#Пример-обучения-с-учителем:-классификация-набора-данных-Iris\" data-toc-modified-id=\"Пример-обучения-с-учителем:-классификация-набора-данных-Iris-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Пример обучения с учителем: классификация набора данных Iris</a></span></li><li><span><a href=\"#Пример-обучения-без-учителя:-понижение-размерности-набора-данных-Iris\" data-toc-modified-id=\"Пример-обучения-без-учителя:-понижение-размерности-набора-данных-Iris-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>Пример обучения без учителя: понижение размерности набора данных Iris</a></span></li><li><span><a href=\"#Обучение-без-учителя:-кластеризация-набора-данных-Iris\" data-toc-modified-id=\"Обучение-без-учителя:-кластеризация-набора-данных-Iris-1.2.5\"><span class=\"toc-item-num\">1.2.5&nbsp;&nbsp;</span>Обучение без учителя: кластеризация набора данных Iris</a></span></li></ul></li><li><span><a href=\"#Прикладная-задача:-анализ-рукописных-цифр\" data-toc-modified-id=\"Прикладная-задача:-анализ-рукописных-цифр-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Прикладная задача: анализ рукописных цифр</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-и-визуализация-цифр\" data-toc-modified-id=\"Загрузка-и-визуализация-цифр-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Загрузка и визуализация цифр</a></span></li><li><span><a href=\"#Обучение-без-учителя:-понижение-размерности\" data-toc-modified-id=\"Обучение-без-учителя:-понижение-размерности-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Обучение без учителя: понижение размерности</a></span></li><li><span><a href=\"#Классификация-цифр\" data-toc-modified-id=\"Классификация-цифр-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Классификация цифр</a></span></li></ul></li><li><span><a href=\"#Резюме\" data-toc-modified-id=\"Резюме-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Резюме</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aB5ql4CMQAVr"
   },
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/PDSH-cover-small.png?raw=1\">\n",
    "\n",
    "*Этот ноутбук содержит сведения из книги [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) Jake VanderPlas; содержимое доступно на [GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jNmUHiGQAV8"
   },
   "source": [
    "# Знакомство с библиотекой Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdF7IcrNQAV9"
   },
   "source": [
    "Существует несколько библиотек языка Python с надежными реализациями широкого диапазона алгоритмов машинного обучения. Одна из самых известных — \n",
    "Scikit-Learn, пакет, предоставляющий эффективные версии множества распространенных алгоритмов. Пакет Scikit-Learn отличает аккуратный, единообразный \n",
    "и продвинутый API, а также удобная и всеохватывающая онлайн-документация. \n",
    "Преимущество этого единообразия в том, что, разобравшись в основах использования и синтаксисе Scikit-Learn для одного типа моделей, вы сможете легко перейти \n",
    "к другой модели или алгоритму.\n",
    "Начнем с представления данных (data representation) в библиотеке Scikit-Learn, \n",
    "затем рассмотрим API Estimator (API статистического оценивания) и, наконец, \n",
    "взглянем на интересный пример использования этих инструментов для исследования набора изображений рукописных цифр."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1sni53_QAV-"
   },
   "source": [
    "## Представление данных в Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gzxPbDQQAV_"
   },
   "source": [
    "Машинное обучение связано с созданием моделей на основе данных, поэтому \n",
    "начнем с обсуждения понятного компьютеру представления данных. Лучше всего представлять используемые в библиотеке Scikit-Learn данные в виде таблиц."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jP2tcseJQAWB"
   },
   "source": [
    "### Данные как таблица\n",
    "\n",
    "Простейшая таблица — двумерная сетка данных, в которой строки представляют \n",
    "отдельные элементы набора данных, а столбцы — атрибуты, связанные с каждым \n",
    "из этих элементов. Например, рассмотрим набор данных Iris (https://en.wikipedia.\n",
    "org/wiki/Iris_flower_data_set), проанализированный Рональдом Фишером в 1936 году. \n",
    "\n",
    "Seaborn - это библиотека для визуализации данных и выделения их статистических особенностей. Seaborn написана поверх библиотеки Matplotlib, но предлагает интерфейс более высокого уровня, а это значит, что \"тонны\" шаблонного кода, формирующего внешний вид графиков, спрятаны \"под капотом\". Чтобы создать график более чем пригодный для быстрой \"разведки\" данных, нужно всего одна-две строчки кода, а если требуется подготовить график для презентации или публикации, то Seaborn также предоставляет доступ к низкоуровневым настройкам.\n",
    "\n",
    "Еще одна важная особенность библиотеки Seaborn - это заложенный в нее механизм предобработки данных, возможный благодаря тесной интеграции с библиотекой Pandas. Данные можно передавать прямо в объектах DataFrame, а Seaborn сама выполнит всю необходимую работу: агрегацию (выделение подмножеств), статистическую обработку (например вычисление доверительных интервалов) и визуальное выделение полученных результатов.\n",
    "\n",
    "Скачаем его в виде объекта DataFrame библиотеки Pandas с помощью библиотеки \n",
    "Seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cm7kx0yuQAWE",
    "outputId": "2ea50364-73d0-4155-8897-17acd70ab488"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "iris = sns.load_dataset('iris')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46oiLSvaQAWI"
   },
   "source": [
    "Каждая строка данных относится к одному из измеренных цветков, а количество \n",
    "строк равно полному количеству цветков в наборе данных. Мы будем называть \n",
    "строки этой матрицы выборками (samples), а количество строк полагать равным \n",
    "n_samples.\n",
    "Каждый столбец данных относится к конкретному количественному показателю, \n",
    "описывающему данную выборку. Мы будем называть столбцы матрицы признаками (features), а количество столбцов полагать равным n_features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwwPF9YfQAWJ"
   },
   "source": [
    "#### Матрица признаков\n",
    "\n",
    "Из устройства таблицы очевидно, что информацию можно рассматривать как \n",
    "двумерный числовой массив или матрицу, которую мы будем называть матрицей признаков (features matrix). По традиции матрицу признаков часто хранят \n",
    "в переменной X. Предполагается, что матрица признаков — двумерная, с формой \n",
    "[n_samples, n_features], и хранят ее чаще всего в массиве NumPy или объекте \n",
    "DataFrame библиотеки Pandas, хотя некоторые модели библиотеки Scikit-Learn \n",
    "допускают использование также разреженных матриц из библиотеки SciPy.\n",
    "Выборки (то есть строки) всегда соответствуют отдельным объектам, описываемым набором данных. Например, выборка может быть цветком, человеком, \n",
    "документом, изображением, звуковым файлом, видеофайлом, астрономическим \n",
    "объектом или чем-то еще, что можно описать с помощью набора количественных \n",
    "измерений.\n",
    "Признаки (то есть столбцы) всегда соответствуют конкретным наблюдениям, \n",
    "описывающим каждую из выборок количественным образом. Значения признаков обычно представляют собой вещественные числа, но в некоторых случаях они \n",
    "могут быть булевыми или иметь дискретные1\n",
    " значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ie7iDNF4QAWL"
   },
   "source": [
    "#### Целевой массив\n",
    "\n",
    "Помимо матрицы признаков x, обычно мы имеем дело с целевым массивом (массивом меток), который принято обозначать y. Целевой массив обычно одномерен, \n",
    "длиной n_samples. Его хранят в массиве NumPy или объекте Series библиотеки \n",
    "Pandas. Значения целевого массива могут быть непрерывными числовыми или \n",
    "дискретными классами/метками. Хотя некоторые оцениватели библиотеки Scikit-Learn умеют работать с несколькими целевыми величинами в виде двумерного \n",
    "целевого массива [n_samples, n_targets], мы в основном будем работать с более \n",
    "простым случаем одномерного целевого массива.\n",
    "Отличительная черта целевого массива от остальных столбцов признаков в том, \n",
    "что он представляет собой величину, значения которой мы хотим предсказать на основе имеющихся данных. Говоря статистическим языком, это зависимая переменная (dependent variable). Например, для предыдущих данных это могла оказаться \n",
    "модель для предсказания вида цветка на основе остальных измерений. В таком \n",
    "случае столбец species рассматривался бы как целевой массив.\n",
    "С учетом вышесказанного можно воспользоваться библиотекой Seaborn, чтобы без труда визуализировать данные (см. рисунок):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tB3pj-1QAWM",
    "outputId": "b2010d94-ffbb-4baa-9104-ba392a9ce0e1"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns; sns.set()\n",
    "sns.pairplot(iris, hue='species', size=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSUvC5sLQAWN"
   },
   "source": [
    "Для использования набора данных Iris в Scikit-Learn мы извлечем матрицу признаков и целевой массив из объекта DataFrame. Сделать это можно с помощью операций объекта DataFrame библиотеки Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8cWL1-zzQAWO",
    "outputId": "4d62f8c2-82f9-4231-d650-6df999e87a3f"
   },
   "outputs": [],
   "source": [
    "X_iris = iris.drop('species', axis=1)\n",
    "X_iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v06cOSrWQAWP",
    "outputId": "d3966f01-6220-4d40-8081-94cd9a2cb511"
   },
   "outputs": [],
   "source": [
    "y_iris = iris['species']\n",
    "y_iris.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLYBGsgbQAWQ"
   },
   "source": [
    "В итоге признаки и целевые величины должны иметь следующий вид:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPrdY1MEQAWR"
   },
   "source": [
    "![](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/figures/05.02-samples-features.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p368ls5vQAWS"
   },
   "source": [
    "Теперь, отформатировав наши данные нужным образом, мы можем перейти к рассмотрению API статистических оценок библиотеки Scikit-Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxycmMWxQAWS"
   },
   "source": [
    "## API статистического оценивания библиотеки Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcviyjCtQAWT"
   },
   "source": [
    "В документации по API Scikit-Learn говорится, что он основывается на следующих \n",
    "принципах:\n",
    "\n",
    " единообразие — интерфейс всех объектов идентичен и основан на ограниченном \n",
    "наборе методов, причем документация тоже единообразна;\n",
    "\n",
    " контроль — видимость всех задаваемых значений параметров как открытых \n",
    "атрибутов;\n",
    "\n",
    " ограниченная иерархия объектов — классы языка Python используются только \n",
    "для алгоритмов; наборы данных представлены в стандартных форматах (массивы \n",
    "NumPy, объекты DataFrame библиотеки Pandas, разреженные матрицы библиотеки \n",
    "SciPy), а для имен параметров используются стандартные строки языка Python;\n",
    "\n",
    " объединение — многие из задач машинного обучения можно выразить в виде последовательностей алгоритмов более низкого уровня, и библиотека Scikit-Learn \n",
    "пользуется этим фактом при любой возможности;\n",
    "\n",
    " разумные значения по умолчанию — библиотека задает для необходимых \n",
    "моделей пользовательских параметров соответствующие значения по умолчанию.\n",
    "\n",
    "На практике эти принципы очень облегчают изучение библиотеки Scikit-Learn. \n",
    "Все алгоритмы машинного обучения в библиотеке Scikit-Learn реализуются через \n",
    "API статистического оценивания, предоставляющий единообразный интерфейс \n",
    "для широкого диапазона прикладных задач машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDT9NmWtQAWU"
   },
   "source": [
    "### Основы API статистического оценивания\n",
    "\n",
    "Чаще всего использование API статистического оценивания библиотеки Scikit-Learn включает следующие шаги (далее мы рассмотрим несколько подробных \n",
    "примеров).\n",
    "1. Выбор класса модели с помощью импорта соответствующего класса оценивателя из библиотеки Scikit-Learn.\n",
    "2. Выбор гиперпараметров модели путем создания экземпляра этого класса с соответствующими значениями.\n",
    "3. Компоновка данных в матрицу признаков и целевой вектор в соответствии \n",
    "с описанным выше.\n",
    "4. Обучение модели на своих данных посредством вызова метода fit() экземпляра \n",
    "модели.\n",
    "5. Применение модели к новым данным:\n",
    " \n",
    " в случае машинного обучения с учителем метки для неизвестных данных \n",
    "обычно предсказывают с помощью метода predict();\n",
    " \n",
    " в случае машинного обучения без учителя выполняется преобразование \n",
    "свойств данных или вывод их значений посредством методов transform()\n",
    "или predict().\n",
    "\n",
    "Рассмотрим несколько простых примеров применения методов обучения без учителя и с учителем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0Kb2ZjUQAWV"
   },
   "source": [
    "### Пример обучения с учителем: простая линейная регрессия\n",
    "\n",
    "В качестве примера этого процесса возьмем простую линейную регрессию, то есть \n",
    "часто встречающийся случай подбора разделяющей прямой для данных вида (x, y). \n",
    "Для этого примера возьмем следующие простые данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fNZtAySnQAWW",
    "outputId": "a0c3f20e-aac7-4cdd-e848-16e49b8f6f67"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "x = 10 * rng.rand(50)\n",
    "y = 2 * x - 1 + rng.randn(50)\n",
    "plt.scatter(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6RErbrOQAWX"
   },
   "source": [
    "Затем мы можем воспользоваться описанным выше рецептом. Пройдемся по всем \n",
    "шагам этого процесса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzilYLKSQAWY"
   },
   "source": [
    "#### 1. Выбор класса модели.\n",
    "\n",
    "Каждый класс модели в библиотеке Scikit-Learn представлен соответствующим \n",
    "классом языка Python. Так, например, для расчета модели простой линейной \n",
    "регрессии можно импортировать класс линейной регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u145KgwQQAWY"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQOQMa8FQAWY"
   },
   "source": [
    "Обратите внимание, что существуют и другие, более общие модели линейной \n",
    "регрессии, прочитать о них подробнее вы можете в документации модуля sklearn.linear_model (http://scikit-learn.org/stable/modules/linear_model.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKbBd7ByQAWZ"
   },
   "source": [
    "#### 2. Выбор гиперпараметров модели.\n",
    "\n",
    "Подчеркнем важный момент: класс модели — не то же самое, что экземпляр \n",
    "модели.\n",
    "После выбора класса модели у нас все еще остаются некоторые возможности для \n",
    "выбора. В зависимости от нашего класса модели может понадобиться ответить \n",
    "на один или несколько следующих вопросов.\n",
    "\n",
    "Хотим ли мы выполнить подбор сдвига прямой (то есть точки пересечения \n",
    "с осью координат)?\n",
    "\n",
    "Хотим ли мы нормализовать модель?\n",
    "\n",
    "Хотим ли мы сделать модель более гибкой, выполнив предварительную обработку признаков?\n",
    "\n",
    "Какая степень регуляризации должна быть у нашей модели?\n",
    "\n",
    "Сколько компонент модели мы хотели бы использовать?\n",
    "\n",
    "Это примеры тех важных решений, которые нам придется принять после выбора \n",
    "класса модели. Результаты этих решений часто называют гиперпараметрами, \n",
    "то есть параметрами, задаваемыми до обучения модели на данных. Выбор \n",
    "гиперпараметров в библиотеке Scikit-Learn осуществляется путем передачи \n",
    "значений при создании экземпляра модели.\n",
    "Создадим экземпляр класса LinearRegression и укажем с помощью гиперпараметра fit_intercept, что нам бы хотелось выполнить подбор точки пересечения \n",
    "с осью координат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lx49cKc-QAWZ",
    "outputId": "69adeaff-fef9-4715-d90e-ec7ea5558116"
   },
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egOOhhSzQAWa"
   },
   "source": [
    "Помните, что при создании экземпляра модели выполняется только сохранение \n",
    "значений этих гиперпараметров. В частности, мы все еще не применили модель \n",
    "ни к каким данным: API библиотеки Scikit-Learn очень четко разделяет выбор \n",
    "модели и применение модели к данным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGFSiwJtQAWa"
   },
   "source": [
    "#### 3. Формирование из данных матриц признаков и целевого вектора.\n",
    "Ранее мы подробно рассмотрели представление данных в библиотеке Scikit-Learn, для которого необходимы двумерная матрица признаков и одномерный \n",
    "целевой вектор. Наша целевая переменная уже имеет нужный вид (массив \n",
    "длиной n_samples), но нам придется проделать небольшие манипуляции с данными x, чтобы сделать из них матрицу размера [n_samples, n_features]. В данном случае манипуляции сводятся просто к изменению формы одномерного \n",
    "массива:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i4P5SulxQAWb",
    "outputId": "ab1fdc84-9029-458a-fca5-6f0bf7fb2d41"
   },
   "outputs": [],
   "source": [
    "X = x[:, np.newaxis]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MToeCO9YQAWb"
   },
   "source": [
    "#### 4. Обучение модели на наших данных.\n",
    "Пришло время применить модель к данным. Сделать это можно с помощью \n",
    "метода fit() модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Td3_G94OQAWc",
    "outputId": "cdc6b34f-1367-4a91-a278-738f4c1201f5"
   },
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIZiA3NRQAWc"
   },
   "source": [
    "Команда fit() вызывает выполнение «под капотом» множества вычислений, \n",
    "в зависимости от модели, и сохранение результатов этих вычислений в атрибутах \n",
    "модели, доступных для просмотра пользователем. В библиотеке Scikit-Learn по традиции все параметры модели, полученные в процессе выполнения команды \n",
    "fit(), содержат в конце названия знак подчеркивания. Например, в данной \n",
    "линейной модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-BfHZF-QAWd",
    "outputId": "b3400470-259a-4f69-e258-41f9f13cf78d"
   },
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKi8oV4hQAWe",
    "outputId": "9aa2e849-f3ef-4963-b29d-2f8ad5db6c60"
   },
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bN0YNJkMQAWe"
   },
   "source": [
    "Эти два параметра представляют собой угловой коэффициент и точку пересечения с осью координат для простой линейной аппроксимации наших данных. \n",
    "Сравнивая с описанием данных, видим, что они очень близки к исходному \n",
    "угловому коэффициенту, равному 2, и точке пересечения, равной –1.\n",
    "Часто возникает вопрос относительно погрешностей в подобных внутренних параметрах модели. В целом библиотека Scikit-Learn не предоставляет \n",
    "инструментов, позволяющих делать выводы непосредственно из внутренних \n",
    "параметров модели: интерпретация параметров скорее вопрос статистического \n",
    "моделирования, а не машинного обучения. Машинное обучение концентрируется \n",
    "в основном на том, что предсказывает модель. Для тех, кто хочет узнать больше \n",
    "о смысле подбираемых параметров модели, существуют другие инструменты, \n",
    "включая пакет StatsModels языка Python (http://statsmodels.sourceforge.net/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-RmtMeKQAWf"
   },
   "source": [
    "#### 5. Предсказание меток для новых данных.\n",
    "После обучения модели главная задача машинного обучения с учителем заключается в вычислении с ее помощью значений для новых данных, не являющихся \n",
    "частью обучающей последовательности. Сделать это в библиотеке Scikit-Learn \n",
    "можно посредством метода predict(). В этом примере наши новые данные будут \n",
    "сеткой x-значений и нас будет интересовать, какие y-значения предсказывает \n",
    "модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTTONdF1QAWg"
   },
   "outputs": [],
   "source": [
    "xfit = np.linspace(-1, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ho77cGtQAWg"
   },
   "source": [
    "Как и ранее, эти x-значения требуется преобразовать в матрицу признаков \n",
    "[n_samples, n_features], после чего можно подать их на вход модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NtjxZ1WcQAWg"
   },
   "outputs": [],
   "source": [
    "Xfit = xfit[:, np.newaxis]\n",
    "yfit = model.predict(Xfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hXfvCthQAWi"
   },
   "source": [
    "Наконец, визуализируем результаты, нарисовав сначала график исходных данных, а затем обученную модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ms9AQd48QAWj",
    "outputId": "f782c65f-c3b9-453e-f806-60597a7bed5f"
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.plot(Xfit, yfit);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvuVr3MQQAWk"
   },
   "source": [
    "Обычно эффективность модели оценивают, сравнивая ее результаты с эталоном, \n",
    "как мы увидим в следующем примере."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f2Avl0vQAWk"
   },
   "source": [
    "### Пример обучения с учителем: классификация набора данных Iris\n",
    "\n",
    "Рассмотрим другой пример того же процесса, воспользовавшись обсуждавшимся \n",
    "ранее набором данных Iris. Зададимся вопросом: насколько хорошо мы сможем \n",
    "предсказать метки остальных данных с помощью модели, обученной на некоторой \n",
    "части данных набора Iris?\n",
    "Для этой задачи мы воспользуемся чрезвычайно простой обобщенной моделью, известной под названием «Гауссов наивный байесовский классификатор», исходящей \n",
    "из допущения, что все классы взяты из выровненного по осям координат Гауссова \n",
    "распределения. Гауссов наивный байесовский классификатор в силу отсутствия гиперпараметров и высокой производительности — хороший кандидат на роль эталонной \n",
    "классификации. Имеет смысл поэкспериментировать с ним, прежде чем выяснять, \n",
    "можно ли получить лучшие результаты с помощью более сложных моделей.\n",
    "Мы собираемся проверить работу модели на неизвестных ей данных, так что \n",
    "необходимо разделить данные на обучающую последовательность (training set) \n",
    "и контрольную последовательность (testing set). Это можно сделать вручную, но \n",
    "удобнее воспользоваться вспомогательной функцией train_test_split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpnW2gCfQAWl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_iris, y_iris,\n",
    "                                                random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eer96kc_QAWl"
   },
   "source": [
    "После упорядочения данных последуем нашему рецепту для предсказания меток:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "peQo-_J_QAWl"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB # 1. choose model class\n",
    "model = GaussianNB()                       # 2. instantiate model\n",
    "model.fit(Xtrain, ytrain)                  # 3. fit model to data\n",
    "y_model = model.predict(Xtest)             # 4. predict on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVHVH-h_QAWl"
   },
   "source": [
    "Воспользуемся утилитой accuracy_score для выяснения того, какая часть предсказанных меток соответствует истинному значению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYZ0kSCpQAWm",
    "outputId": "1af5abc4-c740-40f8-8889-4eadd309b38a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQNDIbelQAWn"
   },
   "source": [
    "Как видим, точность превышает 97%, поэтому для этого конкретного набора данных даже очень наивный алгоритм классификации оказывается эффективным! Про другие метрики библиотеки Scikit-learn можно почитать здесь https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZDFBJD5QAWo"
   },
   "source": [
    "### Пример обучения без учителя: понижение размерности набора данных Iris\n",
    "\n",
    "В качестве примера задачи обучения без учителя рассмотрим задачу понижения размерности набора данных Iris с целью упрощения его визуализации. Напомню, что \n",
    "данные Iris четырехмерны: для каждой выборки зафиксированы четыре признака.\n",
    "Задача понижения размерности заключается в выяснении, существует ли подходящее представление более низкой размерности, сохраняющее существенные \n",
    "признаки данных. Зачастую понижение размерности используется для облегчения визуализации данных, в конце концов, гораздо проще строить график данных \n",
    "в двух измерениях, чем в четырех или более!\n",
    "В этом разделе мы будем использовать метод главных компонент (PCA), представляющий собой быстрый линейный метод понижения размерности. Наша модель должна будет \n",
    "возвращать две компоненты, то есть двумерное представление данных.\n",
    "Следуя вышеописанной последовательности шагов, получаем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HU6T8eHRQAWq"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA  # 1. Choose the model class\n",
    "model = PCA(n_components=2)            # 2. Instantiate the model with hyperparameters\n",
    "model.fit(X_iris)                      # 3. Fit to data. Notice y is not specified!\n",
    "X_2D = model.transform(X_iris)         # 4. Transform the data to two dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhp_mNuzQAWr"
   },
   "source": [
    "Построим график полученных результатов. Сделать это быстрее всего можно, вставив результаты в исходный объект DataFrame Iris и воспользовавшись функцией \n",
    "lmplot для отображения результатов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32eehJhfQAWr",
    "outputId": "b301eeec-b330-46fc-84cd-677f59055683"
   },
   "outputs": [],
   "source": [
    "iris['PCA1'] = X_2D[:, 0]\n",
    "iris['PCA2'] = X_2D[:, 1]\n",
    "sns.lmplot(\"PCA1\", \"PCA2\", hue='species', data=iris, fit_reg=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FXkRuKlQAWs"
   },
   "source": [
    "Мы видим, что в двумерном представлении виды цветов четко разделены, хотя \n",
    "алгоритм PCA ничего не знает о метках видов цветов! Это показывает, что, как мы \n",
    "и видели ранее, даже относительно простая классификация на этом наборе данных, \n",
    "вероятно, будет работать достаточно хорошо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hl5ZFt8EQAWs"
   },
   "source": [
    "### Обучение без учителя: кластеризация набора данных Iris\n",
    "\n",
    "Теперь рассмотрим кластеризацию набора данных Iris. Алгоритм кластеризации \n",
    "пытается выделить группы данных безотносительно к каким-либо меткам. Здесь \n",
    "мы собираемся использовать мощный алгоритм кластеризации под названием \n",
    "смесь Гауссовых распределений (Gaussian mixture model, GMM). Метод GMM состоит в попытке моделирования данных в виде набора \n",
    "Гауссовых пятен.\n",
    "Обучаем смесь Гауссовых распределений следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBAqZ5cRQAWt"
   },
   "outputs": [],
   "source": [
    "from sklearn import mixture          # 1. Choose the model class\n",
    "model = mixture.GaussianMixture(n_components=3, covariance_type='full') # 2. Instantiate the model with hyperparameters \n",
    "model.fit(X_iris)                    # 3. Fit to data. Notice y is not specified!\n",
    "y_gmm = model.predict(X_iris)        # 4. Determine cluster labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCUCcOb0QAWt"
   },
   "source": [
    "Как и ранее, добавим столбец cluster в DataFrame Iris и воспользуемся библиотекой \n",
    "Seaborn для построения графика результатов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEBrb_miQAWt",
    "outputId": "d4b2f912-2b38-41e2-c489-2881099f7dc1"
   },
   "outputs": [],
   "source": [
    "iris['cluster'] = y_gmm\n",
    "sns.lmplot(\"PCA1\", \"PCA2\", data=iris, hue='species',\n",
    "           col='cluster', fit_reg=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGD6McZxQAWu"
   },
   "source": [
    "Разбив данные в соответствии с номерами кластеров, мы видим, насколько хорошо алгоритм GMM восстановил требуемые метки: вид setosa идеально выделен \n",
    "в кластер 0, правда, небольшое количество экземпляров видов versicolor и virginica\n",
    "смешались между собой. Следовательно, даже если у нас нет эксперта, который мог \n",
    "бы сообщить нам, к каким видам относятся отдельные цветки, одних измерений \n",
    "вполне достаточно для автоматического распознания этих различных разновидностей цветков с помощью простого алгоритма кластеризации! Подобный алгоритм \n",
    "может в дальнейшем помочь специалистам по предметной области выяснить связи \n",
    "между исследуемыми образцами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48U2d7IoQAWu"
   },
   "source": [
    "## Прикладная задача: анализ рукописных цифр"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZslNtxuQAWv"
   },
   "source": [
    "Продемонстрируем эти принципы на более интересной задаче, рассмотрев один из \n",
    "аспектов задачи оптического распознавания символов — распознавание рукописных \n",
    "цифр. Традиционно эта задача включает как определение местоположения на рисунке, так и распознание символов. Мы пойдем самым коротким путем и воспользуемся \n",
    "встроенным в библиотеку Scikit-Learn набором переформатированных цифр."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIsmk3cOQAWx"
   },
   "source": [
    "### Загрузка и визуализация цифр\n",
    "\n",
    "Воспользуемся интерфейсом доступа к данным библиотеки Scikit-Learn и посмотрим на эти данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_jmbnBwQAWy",
    "outputId": "9cc563d1-95a2-4c20-8bdb-8df24aa2f188"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.images.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5bTuYcwQAWz"
   },
   "source": [
    "Данные изображений представляют собой трехмерный массив: 1797 выборок, \n",
    "каждая состоит из сетки пикселов размером 8 × 8. Визуализируем первую их сотню"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "878GOBBlQAW0",
    "outputId": "7e99763b-21f2-4b2f-8ffb-bf701d3f3108"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(10, 10, figsize=(8, 8),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(digits.images[i], cmap='binary', interpolation='nearest')\n",
    "    ax.text(0.05, 0.05, str(digits.target[i]),\n",
    "            transform=ax.transAxes, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rj3l5RmyQAW0"
   },
   "source": [
    "Для работы с этими данными в библиотеке Scikit-Learn нам нужно получить их \n",
    "двумерное [n_samples, n_features] представление. Для этого мы будем трактовать каждый пиксел в изображении как признак, то есть «расплющим» массивы \n",
    "пикселов так, чтобы каждую цифру представлял массив пикселов длиной 64 элемента. Кроме этого, нам понадобится целевой массив, задающий для каждой цифры предопределенную метку. Эти два параметра встроены в набор данных цифр \n",
    "в виде атрибутов data и target, соответственно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jKDawGJqQAW1",
    "outputId": "509fd6e7-043e-4deb-b5c5-84e1b9c7ccca"
   },
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dpR1ga9gQAW1",
    "outputId": "db076147-0894-4135-fb95-cfab32e64c0b"
   },
   "outputs": [],
   "source": [
    "y = digits.target\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lro1yfuvQAW2"
   },
   "source": [
    "Итого получаем 1797 выборок и 64 признака."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IarV3eOmQAW2"
   },
   "source": [
    "### Обучение без учителя: понижение размерности\n",
    "\n",
    "Хотелось бы визуализировать наши точки в 64-мерном параметрическом пространстве, но эффективно визуализировать точки в пространстве такой высокой размерности непросто. Понизим вместо этого количество измерений до 2, \n",
    "воспользовавшись методом обучения без учителя. Здесь мы будем применять \n",
    "алгоритм обучения на базе многообразий под названием Isomap и преобразуем \n",
    "данные в двумерный вид:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jiD2MLe8QAW3",
    "outputId": "bc210106-6f52-49ef-acfa-0f917a55f1d4"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "iso = Isomap(n_components=2)\n",
    "iso.fit(digits.data)\n",
    "data_projected = iso.transform(digits.data)\n",
    "data_projected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a793dX6mQAW4"
   },
   "source": [
    "Теперь наши данные стали двумерными. Построим график этих данных, чтобы \n",
    "увидеть, можно ли что-то понять из их структуры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AmRCX1cwQAW4",
    "outputId": "0639a39b-5ece-4c93-d7bb-2c7011cf31a8"
   },
   "outputs": [],
   "source": [
    "plt.scatter(data_projected[:, 0], data_projected[:, 1], c=digits.target,\n",
    "            edgecolor='none', alpha=0.5,\n",
    "            cmap=plt.cm.get_cmap('Spectral', 10))\n",
    "plt.colorbar(label='digit label', ticks=range(10))\n",
    "plt.clim(-0.5, 9.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_KKxKZvuQAW5"
   },
   "source": [
    "Этот график дает нам представление о разделении различных цифр в 64-мерном пространстве. Например, нули (отображаемые фиолетовым цветом) и единицы (отображаемые красным) практически не пересекаются в параметрическом \n",
    "пространстве. На интуитивном уровне это представляется вполне логичным: нули \n",
    "содержат пустое место в середине изображения, а у единиц там, наоборот, чернила. С другой стороны, единицы и четверки на графике располагаются сплошным \n",
    "спектром, что понятно, ведь некоторые люди рисуют единицы со «шляпками», из-за \n",
    "чего они становятся похожи на четверки.\n",
    "В целом различные группы достаточно хорошо разнесены в параметрическом \n",
    "пространстве. Это значит, что даже довольно простой алгоритм классификации \n",
    "с учителем должен работать на них достаточно хорошо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dz_2-RQLQAW5"
   },
   "source": [
    "### Классификация цифр\n",
    "\n",
    "Применим алгоритм классификации к нашим цифрам. Как и в случае с набором \n",
    "данных Iris, разобьем данные на обучающую и контрольную последовательности, после чего обучим на первой из них Гауссову наивную байесовскую модель \n",
    "таким образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vxbyz1buQAW6"
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMCcjBuIQAW6"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(Xtrain, ytrain)\n",
    "y_model = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nMhRohdQAXG"
   },
   "source": [
    "Теперь, осуществив предсказания по нашей модели, мы можем оценить ее точность, сравнив настоящие значения из контрольной последовательности с предсказанными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D28Wos-8QAXH",
    "outputId": "d3301ff1-4c9d-4175-cf72-97f808bb656c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(ytest, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HG9cIdrQAXI"
   },
   "source": [
    "Даже при такой исключительно простой модели мы получили более чем 80%-ную \n",
    "точность классификации цифр! Однако из одного числа сложно понять, где наша \n",
    "модель ошиблась. Для этой цели удобна так называемая матрица различий (confusion \n",
    "matrix), вычислить которую можно с помощью библиотеки Scikit-Learn, а нарисовать \n",
    "посредством Seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VaWumZ6nQAXJ",
    "outputId": "3cefe5e2-2934-4c72-913a-34791f7a71b1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(ytest, y_model)\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False)\n",
    "plt.xlabel('predicted value')\n",
    "plt.ylabel('true value');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktj67vu_QAXJ"
   },
   "source": [
    "Этот рисунок демонстрирует нам места, в которых наш классификатор склонен \n",
    "ошибаться, например, значительное количество двоек ошибочно классифицированы как единицы или восьмерки. Другой способ получения информации \n",
    "о характеристиках модели — построить график входных данных еще раз вместе \n",
    "с предсказанными метками. Мы будем использовать зеленый цвет для правильных \n",
    "меток, и красный — для ошибочных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCkChq-2QAXK",
    "outputId": "2e9d4eb0-5cde-492b-a302-c33a327fcfac"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, 10, figsize=(8, 8),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "test_images = Xtest.reshape(-1, 8, 8)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(test_images[i], cmap='binary', interpolation='nearest')\n",
    "    ax.text(0.05, 0.05, str(y_model[i]),\n",
    "            transform=ax.transAxes,\n",
    "            color='green' if (ytest[i] == y_model[i]) else 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNIQg0glQAXL"
   },
   "source": [
    "Из этого подмножества данных можно почерпнуть полезную информацию относительно мест, в которых алгоритм работает неоптимально. Чтобы поднять \n",
    "нашу точность выше 80 %, можно воспользоваться более сложным алгоритмом, \n",
    "таким как метод опорных векторов, случайные леса или другим методом классификации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание пола по голосу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем датасет с сайта [Kaggle](https://www.kaggle.com) - [Gender Recognition by Voice](https://www.kaggle.com/primaryobjects/voicegender). В данном датасете в качестве признаков выступают различные звуковые характеристики голоса, а в качестве классов - пол (мужчина/женщина). Подробнее о самих признаках можно почитать [на странице датасета](https://www.kaggle.com/primaryobjects/voicegender) (на английском). Нашей целью пока что является просто протестировать на этих данных алгоритм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron as skPerceptron\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/voice.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data['label'] = data['label'].apply(lambda x: 1 if x == 'male' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтобы перемешать данные. Изначально там сначала идут все мужчины, потом все женщины\n",
    "data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.iloc[:int(len(data)*0.7), :-1]  # матрица объекты-признаки\n",
    "y_train = data.iloc[:int(len(data)*0.7), -1]  # истинные значения пола (мужчина/женщина)\n",
    "\n",
    "X_test = data.iloc[int(len(data)*0.7):, :-1]  # матрица объекты-признаки\n",
    "y_test = data.iloc[int(len(data)*0.7):, -1]  # истинные значения пола (мужчина/женщина)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Натренируем  перцептрон из sklearn на этих данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "sk_perceptron = skPerceptron(random_state=RANDOM_SEED)\n",
    "sk_perceptron.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим долю правильных ответов (на тестовых данных):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Точность (доля правильных ответов) перцептрона из sklearn: {:.3f} %'.format(\n",
    "    accuracy_score(y_test.values, sk_perceptron.predict(X_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_9uGwgQQAXM"
   },
   "source": [
    "## Резюме"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4g9sHFFQAXM"
   },
   "source": [
    "В этом разделе мы рассмотрели основные возможности представления данных \n",
    "библиотеки Scikit-Learn, а также API статистического оценивания. Независимо от \n",
    "типа оценивателя применяется одна и та же схема: импорт/создание экземпляра/\n",
    "обучение/предсказание. Вооружившись этой информацией по API статистического \n",
    "оценивания, вы можете, изучив документацию библиотеки Scikit-Learn, начать \n",
    "экспериментировать, используя различные модели для своих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
